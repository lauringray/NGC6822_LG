{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 July 2018\n",
    "-- Laurin Gray\n",
    "\n",
    "This is a notebook to hold all of the functions I've written during this summer so that I don't have to look through all the notebooks to find a specific one.\n",
    "\n",
    "These functions are used to access, manipulate, and plot data from the catalog of Spitzer sources of Khan et al. (2015), matched with sources from Whitelock et al. (2013) in CasJobs, in the process of trying to identify potential red candidates for AGBs/YSOs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.stats import gaussian_kde\n",
    "import csv\n",
    "import pathlib",
    "import os",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in my data from a .csv file saved locally.\n",
    "\n",
    "# all sources\n",
    "phot_data = pd.read_csv('~/Documents/Phot_data/CMDparameters26June2018_lauringray.csv')\n",
    "\n",
    "filter_phot_data = phot_data[(phot_data < 500.0) & (phot_data > -500.0)]\n",
    "\n",
    "# 3-sigma red flagged data\n",
    "flagged_data = pd.read_csv('/Users/lgray/Documents/Phot_data/flagged_vals_23July2018_lauringray.csv')\n",
    "\n",
    "# CMD counts\n",
    "CMD_counts = pd.read_csv('/Users/lgray/Documents/Phot_data/CMD_counting_23July2018_lauringray.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-Sigma Line Functions\n",
    "\n",
    "These functions were written to identify points that are redward of a 3-sigma line on a CMD.  \n",
    "\n",
    "Examples of usage are in the notebook 24July2018_LG_NGC6822_3SigFlagging\n",
    "\n",
    "They use the phot_data (and related filter_phot_data) tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bins(bin_size, y1, y2, xval, yval, err):\n",
    "    \"\"\"\n",
    "    Create bins to hold selected x-values, y-values, and errors, along with the coordinate ID, \n",
    "    depending on the range of y-values they fall into. Fill those bins with the values, and return the bins.\n",
    "    \n",
    "    The user enters the size of the bin they'd like, the range of data to cover, the x and y axes of the CMD,\n",
    "    and the error associated with the x-axis (created above).  \n",
    "    \n",
    "    Note that it is possible to create bins that will have no values in them- these will simply hold a nan spot, \n",
    "    and not create a 3-sigma boundary for that range.\n",
    "    \n",
    "    The bin size and range must be chosen so that the number of bins comes out as a whole number.  \n",
    "    If this is not the case, an error message will print.  \n",
    "    \n",
    "    y1 must be lower than y2.\n",
    "    \n",
    "    xval, yval, and err take the form \"Kmag\" or \"e_kMINUSthreesix\" \n",
    "    (created from renamed filter_phot_data lists i.e. Kmag = filter_phot_data.Kmag.values)\n",
    "    \n",
    "    Call example:\n",
    "        y1 = 11.5 #make sure to change in create_bins definition\n",
    "        y2 = 19.0\n",
    "        bin_size = 0.1\n",
    "        xaxis = jMINUSthreesix\n",
    "        yaxis = threesix\n",
    "        error = e_jMINUSthreesix\n",
    "    \n",
    "        y_bin, x_bin, e_bin, c_bin = create_bins(bin_size, y1, y2, xaxis, yaxis, error)\n",
    "    \"\"\"\n",
    "    \n",
    "    n_bins = (y2 - y1)/bin_size\n",
    "    #print(n_bins)\n",
    "\n",
    "    if n_bins%1 == 0:\n",
    "        n_bins = int(n_bins)\n",
    "    else:\n",
    "        print(\"Error: n_bins is not a whole number!  Choose a different range or bin size.\")\n",
    "    \n",
    "    \n",
    "    y_bins = [[] for x in range(0,n_bins)] # y-values\n",
    "    x_bins = [[] for x in range(0,n_bins)] # x-values\n",
    "    e_bins = [[] for x in range(0,n_bins)] # errors\n",
    "    c_bins = [[] for x in range(0,n_bins)] # IDs\n",
    "\n",
    "    #print(y_bins)\n",
    "\n",
    "    c=0 #row counter\n",
    "    for i in yval:\n",
    "        k = 0 #bin counter\n",
    "        y1 = 8.0\n",
    "        while k < n_bins+1:\n",
    "            if y1 <= i < y1+bin_size:\n",
    "                y_bins[k].append(i)\n",
    "                x_bins[k].append(xval[c])\n",
    "                e_bins[k].append(err[c])\n",
    "                c_bins[k].append(phot_data.ID.values[c])\n",
    "                y1 = y1+bin_size\n",
    "                k = k+1\n",
    "            else:\n",
    "                y1 = y1+bin_size\n",
    "                k = k+1\n",
    "        c = c+1\n",
    "        \n",
    "    return y_bins, x_bins, e_bins, c_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vert_mean(mag_lim, xval, yval):\n",
    "    \"\"\"\n",
    "    Determine the vertical line of the data- the average of the vertical branch.  \n",
    "    To mitigate the effects of other branches, select a mag_lim that excludes where the points diverge.\n",
    "    \n",
    "    Note that this function WILL NOT work for CMDs with a large amount of horizontal spreading i.e. 8.0 vs. 3.6-8.0\n",
    "    \n",
    "    Call example:\n",
    "        lim = 14.0\n",
    "        xaxis = jMINUSthreesix\n",
    "        yaxis = threesix\n",
    "        boundary = vert_mean(lim, xaxis, yaxis)\n",
    "    \"\"\"\n",
    "    \n",
    "    mean = []\n",
    "\n",
    "    c=0\n",
    "    for i in yval:\n",
    "        if i < mag_lim:\n",
    "            mean.append(xval[c])\n",
    "            c = c+1\n",
    "        else:\n",
    "            c = c+1\n",
    "\n",
    "    bound = np.nanmean(mean)\n",
    "    stdev = np.nanstd(mean)\n",
    "\n",
    "    left = bound - 3*stdev\n",
    "    right = bound + 3*stdev\n",
    "\n",
    "    clip = [] # sigma-clipped array\n",
    "    for k in mean:\n",
    "        if left < k < right:\n",
    "            clip.append(k)\n",
    "\n",
    "    boundary = np.nanmean(clip) #this is the average value of the points above the magnitude limit\n",
    "    #print(boundary)\n",
    "    \n",
    "    return boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bound_shift(boundary):\n",
    "    \"\"\"\n",
    "    Create boundaries in region that are 3-sigma away from the vertical mean.  \n",
    "    Input is the return of the vertical mean function.\n",
    "    \n",
    "    If any bins are empty, this function will return a RuntimeWarning: Mean of empty slice. \n",
    "    This is fine, it just holds a nan value in that spot and won't plot a boundary there\n",
    "    \n",
    "    Call example:\n",
    "        bound_shift(boundary)\n",
    "    \"\"\"\n",
    "    \n",
    "    threesig = []\n",
    "    for i in e_bin:\n",
    "        threesig.append(np.nanmean(i)*3)\n",
    "    \n",
    "    # make list of red limit values\n",
    "    redlim = []\n",
    "\n",
    "    for i in threesig:\n",
    "        redlim.append(boundary+i)\n",
    "    \n",
    "    #print(redlim)\n",
    "    return redlim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_flag():\n",
    "    \"\"\"\n",
    "    Evaluate and flag points that are to the right of the 3-sigma boundary.  \n",
    "    IDs of flagged points are then stored in a list and returned.\n",
    "    \n",
    "    It is suggested that when you call the function to a variable, you name it in the format kVS_kMINUSthreesix,\n",
    "    as this will make it easier to tell which datasets belong to which CMDs when they are all in the same file.\n",
    "    \n",
    "    Call example:\n",
    "        new_data = data_flag()\n",
    "    \"\"\"\n",
    "    \n",
    "    IDs = [] #empty set to store IDs\n",
    "\n",
    "    k=0\n",
    "    #for i in x_bin[:75]:  # use instead of below statement if need to exclude below a certain point\n",
    "    for i in x_bin:\n",
    "        coord = c_bin[k]\n",
    "        c=0\n",
    "        for x in i:\n",
    "            if x > redlim[k]:\n",
    "                IDs.append(coord[c])\n",
    "                c=c+1\n",
    "            else: \n",
    "                c=c+1\n",
    "        k = k+1\n",
    "            \n",
    "    print(\"Number of flagged points:\", len(IDs))\n",
    "    #print(\"IDs of points:\", IDs)\n",
    "    return IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(dataset, column=''):\n",
    "    \"\"\"\n",
    "    Function for saving a single column of data at a time.\n",
    "    \n",
    "    Check if the data file already exists.  If it does, add the data on as a new column with a \n",
    "    header you set when you call the function.  If it doesn't, create the file and add the data to it.\n",
    "    \n",
    "    Call example:\n",
    "        column = 'threesixVS_jMINUSthreesix'\n",
    "        save_data(new_data, column)\n",
    "    \"\"\"\n",
    "    \n",
    "    if path.exists():\n",
    "        flagged_points = pd.read_csv(filename)\n",
    "        new_points = pd.DataFrame({column:dataset})\n",
    "\n",
    "        flagged_points= pd.concat([flagged_points, new_points], axis=1)\n",
    "        flagged_points.to_csv(filename, index=False)\n",
    "    else:\n",
    "        f = open(filename, 'w')\n",
    "        writer = csv.writer(f)\n",
    "        #add heading\n",
    "        points_w_header = [column] + dataset\n",
    "\n",
    "        for val in points_w_header:\n",
    "            writer.writerow([val])\n",
    "\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMD Counting\n",
    "\n",
    "These are functions to count how many CMDs flagged points appeared in.  There is only one function, but it is run on however many CMDs you flagged points in.  When running on multiple columns, it may be useful to start with the longest column first, and work down to the shortest.  This will ensure that the most points are sorted on the first run, and the function will run faster each time.\n",
    "\n",
    "This function was used in the notebook 23July2018_LG_NGC6822_CMDCounting\n",
    "\n",
    "This function uses flagged_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CMD_count(col, column_list):\n",
    "    \"\"\"\n",
    "    Before running the function, user defines empty lists of CMD counts as:\n",
    "        in_one = []\n",
    "        in_two = []\n",
    "        in_three = []\n",
    "        in_four = []\n",
    "        in_five = []\n",
    "        in_six = []\n",
    "        in_seven = []\n",
    "        in_eight = []\n",
    "        in_nine = []\n",
    "        in_ten = []\n",
    "    \n",
    "    This is so that the function can be run on multiple columns without erasing the previous lists.\n",
    "    \n",
    "    User chooses a CMD column that they want to use to iterate through the other CMDs (col), and defines a list\n",
    "    including all other columns (column_list).\n",
    "    \n",
    "    For each element in the chosen column, the function goes through the list of columns, \n",
    "    and checks if the element is in a column.  Each time it is, +1 is added to a counter.  The element is then \n",
    "    sorted into a list based on the final value of the counter, after checking to make sure that \n",
    "    the element is not already in that list (so that it can be run on multiple columns).\n",
    "    \n",
    "    The function also prints which row of the chosen column the function is on every 100 rows, \n",
    "    which is useful for estimating progress.\n",
    "    \n",
    "    Call example:\n",
    "        col_list = [fourfiveMINUSeightzero, threesixMINUSeightzero, jMINUSk, \n",
    "                    hMINUSthreesix, jMINUSh, hMINUSfourfive, hMINUSk]\n",
    "        CMD_count(jMINUSthreesix, col_list)\n",
    "    \"\"\"\n",
    "    \n",
    "    k = 1 # row counter\n",
    "    if k < len(col): # so that the program doesn't try to go past the length of the column\n",
    "        for i in col:\n",
    "            if k%100 == 0:\n",
    "                print(\"On row\", k) \n",
    "        \n",
    "            a=1 # CMD counter\n",
    "            for c in column_list:\n",
    "                s = set(c)\n",
    "                if i in s:\n",
    "                    a = a+1\n",
    "        \n",
    "            if a == 1 and int(i) not in in_one: #if the counter is at 1 and the ID has not already been included\n",
    "                in_one.append(int(i))\n",
    "            elif a == 2 and int(i) not in in_two:\n",
    "                in_two.append(int(i))\n",
    "            elif a == 3 and int(i) not in in_three:\n",
    "                in_three.append(int(i))\n",
    "            elif a == 4 and int(i) not in in_four:\n",
    "                in_four.append(int(i))\n",
    "            elif a == 5 and int(i) not in in_five:\n",
    "                in_five.append(int(i))\n",
    "            elif a == 6 and int(i) not in in_six:\n",
    "                in_six.append(int(i))\n",
    "            elif a == 7 and int(i) not in in_seven:\n",
    "                in_seven.append(int(i))\n",
    "            elif a == 8 and int(i) not in in_eight:\n",
    "                in_eight.append(int(i))\n",
    "            elif a == 9 and int(i) not in in_nine:\n",
    "                in_nine.append(int(i))\n",
    "            elif a == 10 and int(i) not in in_ten:\n",
    "                in_ten.append(int(i))\n",
    "                \n",
    "            k = k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Red Candidates\n",
    "\n",
    "These are functions for plotting where red candidates that appear in a minimum number of CMDs fall on the CMDs themselves.  \n",
    "\n",
    "Examples of usage are in the notebook 23July2018_LG_NGC6822_RedCandPlot\n",
    "\n",
    "They use phot_data (& filter_phot_data) and CMD_counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_rows(groups, lengths):\n",
    "    \"\"\"\n",
    "    Some of the ID numbers are wrong (ex. there are two 2118s), which means we can't use the ID to \n",
    "    directly access the row it belongs to. As we go further down, the problem gets worse.\n",
    "    This function finds the correct rows in phot_data for each ID and saves them to a list.\n",
    "\n",
    "    Takes a list of the CMD counts you want to include in the plot (group) (and their corresponding lengths) \n",
    "    and outputs a list of the rows in phot_data which correspond to the IDs in those groups.\n",
    "    \n",
    "    Note that because groups must be a list, even if you are just running one column, \n",
    "    you need to define the column and length in a list first.\n",
    "    \n",
    "    Call example:\n",
    "        cols = [in_eight]\n",
    "        col_len = [230]\n",
    "        eight_rows = corr_rows(cols, col_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    rows = phot_data.ID.values\n",
    "    \n",
    "    phot_rows = []\n",
    "    \n",
    "    d = 0\n",
    "    for j in groups:\n",
    "        group_lim = lengths[d]\n",
    "        k = 0\n",
    "        #print(group_lim)\n",
    "        for i in j:\n",
    "            c = 0 # counter for phot_data rows, resets for each new element i\n",
    "            # use a while loop so that it iterates until the end of the column\n",
    "            while c < 30761 and k < group_lim: # to prevent reaching the end of the column and getting a nan error\n",
    "                if int(i) != rows[c]: # check if i is equivalent to the ID in the current phot_data row\n",
    "                    c = c+1 # if not, move to next row & go back to the top of the while loop\n",
    "                else: # if i IS equivalent\n",
    "                    phot_rows.append(c) # add the current row to corr_rows\n",
    "                    c = 30761 # set c to stop iterating through the rest of the rows (end loop)\n",
    "            k = k+1 # symbolically move onto the next element in in_ten (to stop the while loop at the end of in_ten)\n",
    "        \n",
    "        d = d+1\n",
    "    \n",
    "    return phot_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_lookup(xaxis, yaxis, source_rows):\n",
    "    \"\"\"\n",
    "    Takes the corrected row of a source in the CMD count, then uses it to look up \n",
    "    the x and y values in the phot_data table.\n",
    "    source_rows should come from the output of the corr_rows function.\n",
    "    \n",
    "    This function is called \"coord_lookup\" in the 11July2018 notebook.  Example of use in 23July2018_RedCandPlot nb.\n",
    "    \n",
    "    Call example:\n",
    "        xaxis = jMINUSthreesix\n",
    "        yaxis = threesix\n",
    "        x_flag_8, y_flag_8 = xy_lookup(xaxis, yaxis, eight_rows)\n",
    "    \"\"\"\n",
    "    \n",
    "    x_vals = []\n",
    "    y_vals = []\n",
    "    k = 0 # row counter\n",
    "    for i in source_rows:\n",
    "        x_vals.append(xaxis[i])\n",
    "        y_vals.append(yaxis[i])\n",
    "    \n",
    "    return x_vals, y_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_red_layers(x_flags, y_flags):\n",
    "    \"\"\"\n",
    "    User creates two lists containing all of the flagged x and y points that were separately saved. \n",
    "    The function then iterates through that list and scatterplots each set in a different color.\n",
    "    \n",
    "    This function also requires user to create a col_names list containing the names of each column included in the \n",
    "    final plot in string form.\n",
    "    \n",
    "    The user can choose whether to assign colors evenly based on the number of columns plotted, \n",
    "    or to keep the same colors with each column no matter how many there are.  \n",
    "    To assign evenly, uncomment number = len(x_flags) and colors = [cmap(i) for i in np.linspace(0, 1, number)]\n",
    "    \n",
    "    Called in plot_CMD as plot_red_layers(x_flagged, y_flagged)\n",
    "    \"\"\"\n",
    "    \n",
    "    #number = len(x_flags)  # for even color assignment\n",
    "    cmap = plt.get_cmap('gist_rainbow')\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, 6)] # for consistent color assignment\n",
    "    #colors = [cmap(i) for i in np.linspace(0, 1, number)]  # for even color assignment\n",
    "    \n",
    "    k = 0\n",
    "    for i in x_flags:\n",
    "        plt.scatter(x_flags[k], y_flags[k], c=colors[k], label=col_names[k], s=1)\n",
    "        k = k+1\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_CMD(xaxis, yaxis, x_flagged, y_flagged):\n",
    "    \"\"\"\n",
    "    Plot a CMD, and overplot the values that are flagged in whichever CMD counts were listed in groups (for corr_rows).\n",
    "    \n",
    "    This function DOES have layering capabilities, simply flag points for each individual group separately\n",
    "    and then create lists combining the flagged x & y points.\n",
    "    \n",
    "    Note that axes limits/labels are pre-defined for the 10 CMDs that were checked.\n",
    "    \"\"\"\n",
    "    \n",
    "    # set axis limits & names (so I don't have to do it manually each time I plot)\n",
    "    if yaxis is eightzero:\n",
    "        y1 = 8.0\n",
    "        y2 = 18.0\n",
    "        ylabel = '[8.0]'\n",
    "    elif yaxis is Hmag:\n",
    "        y1 = 11.5\n",
    "        y2 = 19.0\n",
    "        ylabel = 'H'\n",
    "    elif yaxis is Kmag:\n",
    "        y1 = 11.5\n",
    "        y2 = 19.0\n",
    "        ylabel = 'K'\n",
    "    elif yaxis is threesix:\n",
    "        y1 = 11.5\n",
    "        y2 = 19.0\n",
    "        ylabel = '[3.6]'\n",
    "    \n",
    "    if xaxis is threesixMINUSeightzero:\n",
    "        x1 = -2.0\n",
    "        x2 = 7.5\n",
    "        xlabel = '[3.6] - [8.0]'\n",
    "    elif xaxis is fourfiveMINUSeightzero:\n",
    "        x1 = -1.5\n",
    "        x2 = 6.5\n",
    "        xlabel = '[4.5] - [8.0]'\n",
    "    elif xaxis is jMINUSthreesix:\n",
    "        x1 = -0.5\n",
    "        x2 = 6.0\n",
    "        xlabel = 'J - [3.6]'\n",
    "    elif xaxis is jMINUSh:\n",
    "        x1 = -0.5\n",
    "        x2 = 2.5\n",
    "        xlabel = 'J - H'\n",
    "    elif xaxis is hMINUSk:\n",
    "        x1 = -0.5\n",
    "        x2 = 2.0\n",
    "        xlabel = 'H - K'\n",
    "    elif xaxis is hMINUSthreesix:\n",
    "        x1 = -1.5\n",
    "        x2 = 4.0\n",
    "        xlabel = 'H - [3.6]'\n",
    "    elif xaxis is hMINUSfourfive:\n",
    "        x1 = -2.5\n",
    "        x2 = 5.0\n",
    "        xlabel = 'H - [4.5]'\n",
    "    elif xaxis is jMINUSk:\n",
    "        x1 = -0.5\n",
    "        x2 = 4.0\n",
    "        xlabel = 'J - K'\n",
    "    elif xaxis is kMINUSthreesix:\n",
    "        x1 = -2.0\n",
    "        x2 = 3.5\n",
    "        xlabel = 'K - [3.6]'\n",
    "    elif xaxis is kMINUSfourfive:\n",
    "        x1 = -2.5\n",
    "        x2 = 3.5\n",
    "        xlabel = 'K - [4.5]'\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(xaxis,yaxis,',', color='grey')\n",
    "    plt.xlim(x1, x2)\n",
    "    plt.ylim(y2, y1)\n",
    "    plt.xlabel(xlabel, size=12)\n",
    "    plt.ylabel(ylabel, size=12)\n",
    "    \n",
    "    plot_red_layers(x_flagged, y_flagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiered Catalog\n",
    "\n",
    "These are functions for creating the tiered catalog of flagged sources, organized by CMD count.\n",
    "\n",
    "Examples of usage are in the notebook 24July2018_LG_NGC6822_RedCandCatalogs\n",
    "\n",
    "They use phot_data and CMD_counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_rows(groups, lengths):\n",
    "    \"\"\"\n",
    "    Some of the ID numbers are wrong (ex. there are two 2118s), which means we can't use the ID to \n",
    "    directly access the row it belongs to. As we go further down, the problem gets worse.\n",
    "    This function finds the correct rows in phot_data for each ID and saves them to a list.\n",
    "\n",
    "    Takes a list of the CMD counts you want to include in the plot (group) (and their corresponding lengths) \n",
    "    and outputs a list of the rows in phot_data which correspond to the IDs in those groups.\n",
    "    \n",
    "    Note that because groups must be a list, even if you are just running one column, \n",
    "    you need to define the column and length in a list first (ex. groups = [in_ten]; corr_rows(groups, lengths)).\n",
    "    \n",
    "    For the tiered catalogue, list the columns in order of most to least confidence.\n",
    "    \n",
    "    Call example:\n",
    "        group = [in_eight, in_seven, in_six, in_five, in_four]\n",
    "        length = [230, 137, 215, 243, 250]\n",
    "\n",
    "        source_rows = corr_rows(group, length)\n",
    "    \"\"\"\n",
    "    \n",
    "    rows = phot_data.ID.values\n",
    "    \n",
    "    phot_rows = []\n",
    "    \n",
    "    d = 0\n",
    "    for j in groups:\n",
    "        group_lim = lengths[d]\n",
    "        k = 0\n",
    "        #print(group_lim)\n",
    "        for i in j:\n",
    "            c = 0 # counter for phot_data rows, resets for each new element i\n",
    "            # use a while loop so that it iterates until the end of the column\n",
    "            while c < 30761 and k < group_lim: # to prevent reaching the end of the column and getting a nan error\n",
    "                if int(i) != rows[c]: # check if i is equivalent to the ID in the current phot_data row\n",
    "                    c = c+1 # if not, move to next row & go back to the top of the while loop\n",
    "                else: # if i IS equivalent\n",
    "                    phot_rows.append(c) # add the current row to corr_rows\n",
    "                    c = 30761 # set c to stop iterating through the rest of the rows (end loop)\n",
    "            k = k+1 # symbolically move onto the next element in in_ten (to stop the while loop at the end of in_ten)\n",
    "        \n",
    "        d = d+1\n",
    "    \n",
    "    return phot_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_lookup(source_rows):\n",
    "    \"\"\"\n",
    "    Takes the row of a source in the CMD count, then uses it to look up the related RA, Dec, & magnitudes\n",
    "    in the phot_data table.  source_rows should come from the output of the corr_rows function.\n",
    "    \n",
    "    It is very similar to xy_lookup, but accesses all of the data associated with that ID instead of \n",
    "    just the desired x and y axes.\n",
    "    \n",
    "    This function is called \"coord_lookup\" in the 24July2018_RedCandCat notebook.\n",
    "    \n",
    "    Call example:\n",
    "        ID, RA, Dec, k36mag, k45mag, k58mag, k80mag, k24mag, Jmag, Hmag, Kmag, \n",
    "            jMINUSh, hMINUSk, jMINUSk = mag_lookup(source_rows)\n",
    "    \"\"\"\n",
    "    \n",
    "    ID = []\n",
    "    RA = []\n",
    "    Dec = []\n",
    "    k36mag = []\n",
    "    k45mag = []\n",
    "    k58mag = []\n",
    "    k80mag = []\n",
    "    k24mag = []\n",
    "    Jmag = []\n",
    "    Hmag = []\n",
    "    Kmag = []\n",
    "    jMINUSh = []\n",
    "    hMINUSk = []\n",
    "    jMINUSk = []\n",
    "    \n",
    "    k = 0 # row counter\n",
    "    for i in source_rows:\n",
    "        ID.append(phot_data.ID.values[i])\n",
    "        RA.append(phot_data.RA.values[i])\n",
    "        Dec.append(phot_data.Dec.values[i])\n",
    "        k36mag.append(phot_data.k36mag.values[i])\n",
    "        k45mag.append(phot_data.k45mag.values[i])\n",
    "        k58mag.append(phot_data.k58mag.values[i])\n",
    "        k80mag.append(phot_data.k80mag.values[i])\n",
    "        k24mag.append(phot_data.k24mag.values[i])\n",
    "        Jmag.append(phot_data.Jmag.values[i])\n",
    "        Hmag.append(phot_data.Hmag.values[i])\n",
    "        Kmag.append(phot_data.Kmag.values[i])\n",
    "        jMINUSh.append(phot_data.jMINUSh.values[i])\n",
    "        hMINUSk.append(phot_data.hMINUSk.values[i])\n",
    "        jMINUSk.append(phot_data.jMINUSk.values[i])\n",
    "    \n",
    "    return ID, RA, Dec, k36mag, k45mag, k58mag, k80mag, k24mag, Jmag, Hmag, Kmag, jMINUSh, hMINUSk, jMINUSk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_lookup(source_rows):\n",
    "    \"\"\"\n",
    "    Takes the row of a source in the CMD count, then uses it to look up the related RA, Dec, & magnitudes\n",
    "    in the phot_data table.  source_rows should come from the output of the corr_rows function.\n",
    "    \n",
    "    It is very similar to mag_lookup, but accesses all of the errors associated with the magnitudes instead of \n",
    "    just the magnitudes.  Use in concert with mag_lookup to produce a full set of lists to put into a catalog.\n",
    "    mag_lookup & error_lookup were originally one function, but calling them was a pain and it was easy to make \n",
    "    mistakes, so I split them into two.  This way, you can also create a catalog with only the magnitudes\n",
    "    \n",
    "    \n",
    "    Call example:\n",
    "        e36mag, e45mag, e58mag, e80mag, e24mag, eJmag, eHmag, eKmag, = error_lookup(source_rows)\n",
    "    \"\"\"\n",
    "    \n",
    "    e36mag = []\n",
    "    e45mag = []\n",
    "    e58mag = []\n",
    "    e80mag = []\n",
    "    e24mag = []\n",
    "    eJmag = []\n",
    "    eHmag = []\n",
    "    eKmag = []\n",
    "    \n",
    "    k = 0 # row counter\n",
    "    for i in source_rows:\n",
    "        e36mag.append(phot_data.e36mag.values[i])\n",
    "        e45mag.append(phot_data.e45mag.values[i])\n",
    "        e58mag.append(phot_data.e58mag.values[i])\n",
    "        e80mag.append(phot_data.e80mag.values[i])\n",
    "        e24mag.append(phot_data.e24mag.values[i])\n",
    "        eJmag.append(phot_data.eJmag.values[i])\n",
    "        eHmag.append(phot_data.eHmag.values[i])\n",
    "        eKmag.append(phot_data.eKmag.values[i])\n",
    "    \n",
    "    return e36mag, e45mag,e58mag, e80mag, e24mag, eJmag, eHmag, eKmag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cat(filename):\n",
    "    \"\"\"\n",
    "    Saves produced tiered catalogue of red candidates to a csv file.  \n",
    "    Note that the file MUST NOT previously exist or else this function will just \n",
    "    add the new columns to the previously existing file.\n",
    "    \n",
    "    I didn't actually use this function in the catalog notebook, and as such it doesn't include the error columns.\n",
    "    \n",
    "    Call example:\n",
    "        filename = '/Users/lgray/Documents/Phot_data/RedCandTiers_24July2018_lauringray.csv'\n",
    "        save_cat(filename)\n",
    "    \"\"\"\n",
    "    \n",
    "    f = open(filename, 'w')\n",
    "    writer = csv.writer(f)\n",
    "    #add heading\n",
    "    points_w_header = ['ID'] + ID\n",
    "\n",
    "    for val in points_w_header:\n",
    "        writer.writerow([val])\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    # list of other columns\n",
    "    cols = [RA, Dec, k36mag, k45mag, k58mag, k80mag, k24mag, Jmag, Hmag, Kmag, jMINUSh, hMINUSk, jMINUSk]\n",
    "    headers = ['RA', 'Dec', 'k36mag', 'k45mag', 'k58mag', 'k80mag', 'k24mag', 'Jmag', 'Hmag',\n",
    "           'Kmag', 'jMINUSh', 'hMINUSk', 'jMINUSk']\n",
    "\n",
    "    c=0\n",
    "    for i in cols:\n",
    "        data = pd.read_csv(filename)\n",
    "        new_col = pd.DataFrame({headers[c]:i})\n",
    "        c = c+1\n",
    "\n",
    "        data= pd.concat([data, new_col], axis=1)\n",
    "        data.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_colors(filename, colors):\n",
    "    \"\"\"\n",
    "    Create the colors you want in a catalog.\n",
    "    \n",
    "    I only included the colors for the eight CMDs that we're currently using, but any color can be coded in.\n",
    "    \n",
    "    Call example:\n",
    "        filename = '/Users/lgray/Documents/Phot_data/Red_Cand_Catalogs/24July2018/24July2018_LG_RedCand_8.csv'\n",
    "        colors = ['jMINUSthreesix', 'threesixMINUSeightzero', 'fourfiveMINUSeightzero', \n",
    "                'hMINUSthreesix', 'hMINUSfourfive']\n",
    "    \"\"\"\n",
    "    \n",
    "    header = []\n",
    "    \n",
    "    for name in colors:\n",
    "        catalog = pd.read_csv(filename)\n",
    "        \n",
    "        if name is 'jMINUSthreesix':\n",
    "            catalog[name] = catalog.Jmag.values - catalog.k36mag.values\n",
    "            catalog.to_csv(filename, index=False)\n",
    "        if name is 'threesixMINUSeightzero':\n",
    "            catalog[name] = catalog.k36mag.values - catalog.k80mag.values\n",
    "            catalog.to_csv(filename, index=False)\n",
    "        if name is 'fourfiveMINUSeightzero':\n",
    "            catalog[name] = catalog.k45mag.values - catalog.k80mag.values\n",
    "            catalog.to_csv(filename, index=False)\n",
    "        if name is 'hMINUSthreesix':\n",
    "            catalog[name] = catalog.Hmag.values - catalog.k36mag.values\n",
    "            catalog.to_csv(filename, index=False)\n",
    "        if name is 'hMINUSfourfive':\n",
    "            catalog[name] = catalog.Hmag.values - catalog.k45mag.values\n",
    "            catalog.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SED fitting\n",
    "\n",
    "SED fitting for AGBs will be done with the Dusty Evolved Star Kit (DESK) produced by Steven Goldman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_sep(catalog, folder):\n",
    "    \"\"\"\n",
    "    Each source needs to be in its own csv file with wavelengths (in microns, not JHK) in the first column \n",
    "    and corresponding flux densities (converted from magnitudes to Janskys) in the second column \n",
    "    to run through the Dusty Evolved Star Kit (DESK) for SED fitting.\n",
    "    \n",
    "    This function goes through each row in a catalog, finds the magnitudes for that source, converts the magnitude\n",
    "    to a flux density in units of Janskys, creates a csv file for the source (named the same as the ID), \n",
    "    and writes the wavelength & the flux density into the columns of the file.\n",
    "    \n",
    "    Note that you must create the folder you wish to put the contents of each catalog into \n",
    "    before running the function, and make sure that filename in the function definition points where you want it to.\n",
    "    Additionally, you must include a / at the end of the folder name when you create the folder variable.\n",
    "    \n",
    "    catalog is a pandas dataframe object, and folder is a string.\n",
    "    \n",
    "    The wavelengths and flux zero points are from:\n",
    "    http://www.astro.sunysb.edu/aevans/PHY523/classnotes523/useful-definitions-pp.pdf (for JHK)\n",
    "    IRAC Instrument handbook (for 3.6, 4.5, 5.8, & 8.0)\n",
    "    MIPS Instrument handbook (for 24)\n",
    "    \n",
    "    Call example:\n",
    "        catalog = pd.read_csv('/Users/lgray/Documents/Phot_data/Red_Cand_Catalogs/24July2018/24July2018_LG_RedCand_8.csv')\n",
    "        folder = 'in_eight/'\n",
    "        source_sep(catalog, folder)\n",
    "    \"\"\"\n",
    "    \n",
    "    ID = catalog.ID.values\n",
    "    col_list = ['Jmag', 'Hmag', 'Kmag', 'k36mag', 'k45mag', 'k58mag', 'k80mag', 'k24mag']\n",
    "    wavelengths = [1.22, 1.63, 2.19, 3.6, 4.5, 5.8, 8.0, 24] # wavelengths in microns\n",
    "    f0 = [1570, 1020, 636, 280.9, 179.7, 115.0, 64.9, 7.17] # flux zero points for each wavelength in Jy\n",
    "    \n",
    "    c=0\n",
    "    for index, row in catalog.iterrows():\n",
    "        mags = []\n",
    "        for col in col_list:\n",
    "            mags.append(row[col])\n",
    "        \n",
    "        # Convert mags to flux density (fd) in Janskys\n",
    "        # fd = f0 * 10^(-mag/2.5)\n",
    "        flux_dens = []\n",
    "        j = 0\n",
    "        for i in mags:\n",
    "            exp = i/-2.5\n",
    "            fd = f0[j]*np.power(10, exp)\n",
    "            j = j+1\n",
    "            flux_dens.append(fd)\n",
    "        \n",
    "        # Save to file\n",
    "        filename = '/Users/lgray/Documents/Phot_data/SED_Fit_Sources/24July2018/'+folder+str(ID[c])+'.csv'\n",
    "        c = c+1\n",
    "    \n",
    "        f = open(filename, 'w')\n",
    "        writer = csv.writer(f)\n",
    "    \n",
    "        k = 0\n",
    "        for w in wavelengths:\n",
    "            writer.writerow([w, flux_dens[k]])\n",
    "            k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_key(string_):\n",
    "    \"\"\"\n",
    "    Function for natural sorting of file list (i.e. 1, 3, 20, 108 instead of 1, 108, 20, 3)\n",
    "    From: \n",
    "    https://stackoverflow.com/questions/2545532/python-analog-of-natsort-function-sort-a-list-using-a-natural-order-algorithm\n",
    "    See http://www.codinghorror.com/blog/archives/001018.html\n",
    "    \"\"\"\n",
    "    \n",
    "    return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_desk():\n",
    "    \"\"\"\n",
    "    Function for easily running DESK SED fitting routines produced by Dr. Steven Goldman \n",
    "    (https://github.com/s-goldman/Dusty-Evolved-Star-Kit).\n",
    "    \n",
    "    Function runs the DESK scripts on one file at a time, where each file is a csv of the wavelengths \n",
    "    and flux densities of an individual source.  Source files for a red candidate tier should be within the \n",
    "    same folder, accessed by dir_src.  The function creates master lists of the fitting results & plotting outputs\n",
    "    for all the sources within a tier, while keeping the plots for each source separate.\n",
    "    \n",
    "    Within the code, dir_dest should be changed by the user to point to the \"put_target_data_here\" folder of DESK \n",
    "    within their own computer.  dir_plot is the location of where the user wants to store the individual plots \n",
    "    (recommended to create a folder for each tier in this location before running function).  \n",
    "    The last part of the address for dir_src and dir_plot need to be the same (since they're both sorted by tier).\n",
    "    dir_outputs needs to be changed by the user to point to the DESK folder (where the raw output csvs are stored)\n",
    "    \n",
    "    Before calling function, the user defines:\n",
    "        # variables to stay the same every time the code runs\n",
    "        dir_src = '/Users/lgray/Documents/Phot_data/SED_Fit_Sources/24July2018/'\n",
    "        dir_dest = '/Users/lgray/anaconda3/lib/python3.6/site-packages/desk/put_target_data_here/' \n",
    "        dir_plot = '/Users/lgray/Documents/Phot_data/SED_Plots/'\n",
    "        dir_outputs = '/Users/lgray/anaconda3/lib/python3.6/site-packages/desk/'\n",
    "        single_fitting_results = dir_outputs + 'fitting_results.csv'\n",
    "        single_plot_output = dir_outputs + 'fitting_plotting_outputs.csv'\n",
    "        \n",
    "        # variables that will be input into the function to choose which data to run SED fits for\n",
    "        folder = 'in_eight/'\n",
    "        catalog = pd.read_csv('/Users/lgray/Documents/Phot_data/Red_Cand_Catalogs/24July2018/24July2018_LG_RedCand_8.csv')\n",
    "        master_result = '/Users/lgray/Documents/Phot_data/SED_Fit_Results/fitting_results_8.csv'\n",
    "        master_plot_output = '/Users/lgray/Documents/Phot_data/SED_Plot_Output/fitting_plotting_outputs_8.csv'\n",
    "    \n",
    "    User also defines natural_key (see function notebook) and \n",
    "        %cd '/Users/lgray/anaconda3/lib/python3.6/site-packages/desk/python_scripts'\n",
    "    into the directory for the scripts before running this function.\n",
    "    \n",
    "    Other notes:\n",
    "        - To avoid printing the output for every single source, comment out those lines in sed_fitting.py\n",
    "        - Make sure to adjust the options in sed_fitting.py as desired.\n",
    "        - All folders that data is being created in or moved to must exist before running the function.\n",
    "    \"\"\"\n",
    "    \n",
    "    list_of_sources = catalog.ID.values # list of just the sources in the current tier\n",
    "    list_of_files = os.listdir(dir_src+folder) # list of the filenames in the tier, i.e. '86.csv'\n",
    "    list_of_files = sorted(list_of_files, key=natural_key) # sorted with natural sorting\n",
    "    \n",
    "    #list_of_files = ['85.csv', '106.csv', '170.csv'] # run with just 3 files to make sure it works\n",
    "    \n",
    "    c = 0\n",
    "    for src in list_of_files:\n",
    "        if c == 0:\n",
    "            os.system('rm ' + dir_dest+'*.csv') # empty place_target_data_here\n",
    "            os.system('cp ' + dir_src+folder+src+ ' ' + dir_dest) # cp dir_src+src dir_dest\n",
    "            %run sed_fitting.py\n",
    "            %run plotting_seds.py\n",
    "        \n",
    "        \n",
    "            # read fitting_results.csv into a new file in dir_result\n",
    "            master_fit = open(master_result, 'w') # master file\n",
    "            sing_fit = open(single_fitting_results, 'r')\n",
    "            writer = csv.writer(master_fit) # writer on master fit file\n",
    "            reader = csv.reader(sing_fit) # reader on single fit file\n",
    "\n",
    "            for row in reader:\n",
    "                data = row\n",
    "\n",
    "            writer.writerow(['source', 'L', 'vexp_predicted', 'teff', 'tinner', \n",
    "                             'odep', 'mdot']) # write headers (only 1st)\n",
    "            writer.writerow(data) # write row of data to master file\n",
    "            master_fit.close()\n",
    "            sing_fit.close()\n",
    "        \n",
    "        \n",
    "            # read fitting_plotting_outputs.csv into a new file in dir_result\n",
    "            master_plot = open(master_plot_output, 'w')\n",
    "            sing_plot_output = open(single_plot_output, 'r')\n",
    "            writer = csv.writer(master_plot)\n",
    "            reader = csv.reader(sing_plot_output)\n",
    "\n",
    "            for row in reader:\n",
    "                data = row\n",
    "\n",
    "            writer.writerow(['target_name', 'data_file', 'norm', 'index', 'grid_name', 'teff', 'tinner', 'number', \n",
    "                             'odep', 'mdot', 'vexp'])\n",
    "            writer.writerow(data)\n",
    "            master_plot.close()\n",
    "            sing_plot_output.close()\n",
    "        \n",
    "        \n",
    "            # move plot & rename\n",
    "            os.system('mv ' + dir_outputs+'output_seds.png' + ' ' + dir_plot+folder) # move plot to my plot directory\n",
    "            # rename plot with source ID\n",
    "            os.rename(dir_plot+folder+'output_seds.png', dir_plot+folder+str(catalog.ID.values[c])+'.png') \n",
    "            c = c+1\n",
    "        \n",
    "        else:\n",
    "            #print progress updates every 10 sources (helpful if printing is commented out in sed_fitting.py)\n",
    "            if c%10 == 0:\n",
    "                print('On source ', c, '/', len(list_of_files))\n",
    "            \n",
    "            k = c-1\n",
    "            os.system('rm ' + dir_dest+list_of_files[k]) # remove previous file\n",
    "            os.system('cp ' + dir_src+folder+src + ' ' + dir_dest)  \n",
    "            %run sed_fitting.py\n",
    "            %run plotting_seds.py\n",
    "        \n",
    "        \n",
    "            # read fitting_results.csv into existing file in dir_result\n",
    "            master_fit = pd.read_csv(master_result)\n",
    "            sing_fit = pd.read_csv(single_fitting_results)\n",
    "\n",
    "            master_fit = pd.concat([master_fit, sing_fit], axis=0)\n",
    "            master_fit.to_csv(master_result, index=False)\n",
    "        \n",
    "        \n",
    "            # read fitting_plotting_outputs.csv into existing file in dir_result\n",
    "            master_plot = pd.read_csv(master_plot_output)\n",
    "            sing_plot_output = pd.read_csv(single_plot_output)\n",
    "\n",
    "            master_plot = pd.concat([master_plot, sing_plot_output], axis=0)\n",
    "            master_plot.to_csv(master_plot_output, index=False)\n",
    "        \n",
    "        \n",
    "            # move plot & rename\n",
    "            os.system('mv ' + dir_outputs+'output_seds.png' + ' ' + dir_plot+folder)\n",
    "            os.rename(dir_plot+folder+'output_seds.png', dir_plot+folder+str(catalog.ID.values[c])+'.png')\n",
    "            c = c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
